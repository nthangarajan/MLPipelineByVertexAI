{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92642482",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871cfa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform==1.3.0 in ./.local/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.3.0) (1.31.2)\n",
      "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.3.0) (1.42.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.3.0) (2.26.0)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.3.0) (1.19.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.3.0) (21.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (57.4.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (2021.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (3.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (2.25.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (1.16.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (1.35.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (1.38.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (4.2.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.3.0) (2.0.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.3.0) (2.0.0)\n",
      "Requirement already satisfied: google-crc32c<=1.1.2,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.3.0) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<=1.1.2,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.3.0) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<=1.1.2,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.3.0) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform==1.3.0) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.3.0) (1.26.6)\n",
      "Requirement already satisfied: kfp in ./.local/lib/python3.7/site-packages (1.8.2)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in ./.local/lib/python3.7/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.42.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in ./.local/lib/python3.7/site-packages (from kfp) (1.12.8)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in ./.local/lib/python3.7/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in ./.local/lib/python3.7/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: absl-py<=0.11,>=0.9 in ./.local/lib/python3.7/site-packages (from kfp) (0.11.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.16.0)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.8.2)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in ./.local/lib/python3.7/site-packages (from kfp) (1.7.0)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.10.0.2 in ./.local/lib/python3.7/site-packages (from kfp) (3.10.0.2)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in ./.local/lib/python3.7/site-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: cloudpickle<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.6.0)\n",
      "Requirement already satisfied: click<8,>=7.1.1 in ./.local/lib/python3.7/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in ./.local/lib/python3.7/site-packages (from kfp) (0.10)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.10 in ./.local/lib/python3.7/site-packages (from kfp) (0.1.11)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in ./.local/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<=0.11,>=0.9->kfp) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.12.1)\n",
      "Requirement already satisfied: termcolor in ./.local/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.19.1)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (1.31.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (57.4.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2021.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2.25.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (21.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.0.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.0.2)\n",
      "Requirement already satisfied: google-crc32c<=1.1.2,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<=1.1.2,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<=1.1.2,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (2.20)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (2.4.7)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (4.8.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.5.30)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.6)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2.10)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp) (3.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install {USER_FLAG} google-cloud-aiplatform==1.3.0 --upgrade\n",
    "!pip3 install {USER_FLAG} kfp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e341f2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.2\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5f1f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-cloud-aiplatform        1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520f6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        component,\n",
    "                        OutputPath,\n",
    "                        ClassificationMetrics)\n",
    "\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eec780d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://micronbucket/pipeline_root'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This shell-command outputs default project\n",
    "PROJECT_ID =\"XXXXXXXXXXXX\"\n",
    "REGION = \"XXXXXXXXXXXX\"\n",
    "BUCKET_NAME = \"gs://XXXXXXXXXXXX\"\n",
    "\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "USER = \"Thanga\"\n",
    "PIPELINE_ROOT = \"{}/pipeline_root\".format(BUCKET_NAME)\n",
    "# If there are multiple users, it is better to use username in path:\n",
    "# PIPELINE_ROOT = \"{}/pipeline_root/{}\".format(BUCKET_NAME, USER)\n",
    "\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c002a2",
   "metadata": {},
   "source": [
    "ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3bbfe9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\",\"sklearn\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"data_ingestion.yaml\"\n",
    ")\n",
    "def data_ingestion(\n",
    "    bq_table: str,\n",
    "    dataset_raw: Output[Dataset]\n",
    "):\n",
    "    #Query data warehouse and return dataframe\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "\n",
    "    bqclient = bigquery.Client()\n",
    "    table = bigquery.TableReference.from_string(bq_table)\n",
    "    rows = bqclient.list_rows(table)\n",
    "    \n",
    "    dataframe = rows.to_dataframe(create_bqstorage_client=True,)\n",
    "    \n",
    "    dataframe = dataframe.sample(frac=1, random_state=2)\n",
    "    \n",
    "    dataframe.to_csv(dataset_raw.path,index = False)\n",
    "    \n",
    "    import logging\n",
    "    logging.info(\"deployment decision is %s\", dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ff8d47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"sklearn\", \"pandas\", \"imblearn\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"data_preprocessing.yaml\",\n",
    ")\n",
    "def data_preprocessing(\n",
    "    dataset_raw: Input[Dataset],\n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset]\n",
    "):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from collections import Counter\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(dataset_raw.path)\n",
    "    \n",
    "    #Null value handling\n",
    "    df = df.fillna(df.mean())\n",
    "    \n",
    "    #Normalization\n",
    "    X = df.drop('target' , axis =1)\n",
    "    y = df['target']\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    minMaxScaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(minMaxScaler.fit_transform(X), columns = X.columns)\n",
    "    \n",
    "    # Handling imbalanced dataset\n",
    "    \n",
    "    #smote = SMOTE()\n",
    "    #x_smote, y_smote = smote.fit_resample(X, y)\n",
    "    #balanced_dataframe = pd.concat([pd.DataFrame(x_smote),pd.DataFrame(y_smote)], axis=1)\n",
    "    #df = balanced_dataframe\n",
    "    df = pd.concat([pd.DataFrame(X),pd.DataFrame(y)], axis=1)\n",
    "    \n",
    "    train, test = train_test_split(df, test_size=0.3)\n",
    "    \n",
    "    train.to_csv(dataset_train.path,index = False)\n",
    "    test.to_csv(dataset_test.path,index = False)\n",
    "    \n",
    "    import logging\n",
    "    logging.info(\"deployment decision is %s\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1a67a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"sklearn\", \"pandas\", \"joblib\",\"imblearn\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"model_training.yaml\",\n",
    ")\n",
    "def model_training(\n",
    "    dataset_train: Input[Dataset],\n",
    "    model: Output[Model]):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from joblib import dump\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_csv(dataset_train.path)\n",
    "    \n",
    "    X_train = df.drop('target' , axis =1)\n",
    "    y_train = df['target']\n",
    "    \n",
    "    skmodel = RandomForestClassifier( min_samples_leaf = 1, max_features= 'auto', criterion= 'entropy', bootstrap= False)\n",
    "    skmodel.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate score.First argument is X, second is Y. \n",
    "    score = skmodel.score(X_train,y_train)\n",
    "    y_pred = skmodel.predict(X_train)\n",
    "    \n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    \n",
    "    f1_score_value = f1_score(y_train, y_pred, average='weighted')\n",
    "    precision_score_value = precision_score(y_train, y_pred, average='weighted')\n",
    "    recall_value = recall_score(y_train, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "     # We can reach model's metadata.\n",
    "    model.metadata[\"Training_score\"] = (score * 100.0) \n",
    "    model.metadata[\"Training_DataSize\"] = len(df)\n",
    "    \n",
    "    model.metadata[\"Training_f1_score\"] = (f1_score_value * 100.0)\n",
    "    model.metadata[\"Training_precision_score\"] = (precision_score_value * 100.0)\n",
    "    model.metadata[\"Training_recall_score\"] = (recall_value * 100.0)\n",
    "    \n",
    "    model.metadata[\"Classificaton Algorithm\"] = \"RandomForestClassifier\" # We define this metadata.\n",
    "    \n",
    "    dump(skmodel, model.path + \".joblib\")\n",
    "    print (model.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4575522",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install = [\"pandas\",\"sklearn\",\"numpy\",\"joblib\"],\n",
    "          base_image=\"python:3.9\",\n",
    "          output_component_file=\"evaluation_model.yaml\",)\n",
    "def evaluation_model(\n",
    "    dataset_test: Input[Dataset],\n",
    "    model: Input[Model],\n",
    "    metrics: Output[Metrics]\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import logging\n",
    "    \n",
    "    df = pd.read_csv(dataset_test.path)\n",
    "\n",
    "    X_test = df.drop('target' , axis =1)\n",
    "    y_test = df['target']\n",
    "    \n",
    "    import joblib\n",
    "    skmodel = joblib.load(model.path  + \".joblib\")\n",
    "\n",
    "    score = skmodel.score(X_test,y_test)\n",
    "    y_pred = skmodel.predict(X_test)\n",
    "    \n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    \n",
    "    f1_score_value = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision_score_value = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall_value = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    \n",
    "    \n",
    "    metrics.log_metric(\"f1_score\", (f1_score_value * 100.0))\n",
    "    metrics.log_metric(\"precision\" , (precision_score_value * 100.0))\n",
    "    metrics.log_metric(\"recall\",(recall_value * 100.0))\n",
    "    metrics.log_metric(\"accuracy\",(score * 100.0))\n",
    "    \n",
    "    model.metadata[\"Testing_score\"] = (score * 100.0)\n",
    "    model.metadata[\"Testing_DataSize\"] = len(df)\n",
    "    \n",
    "    if ((f1_score_value * 100.0) >= 97.0):\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    \n",
    "    logging.info(\"deployment decision is f1_score %f\", (f1_score_value * 100.0))\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "    \n",
    "    return (dep_decision, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "abb80139",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install = [\"google-cloud-bigquery\", \"pandas\",\"sklearn\",\"numpy\", \"joblib\", \"pyarrow\"],\n",
    "          base_image=\"python:3.9\",\n",
    "          output_component_file=\"evaluation_model.yaml\",)\n",
    "def model_inference(\n",
    "    dataset_raw: Input[Dataset],\n",
    "    model: Input[Model]):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import logging\n",
    "    \n",
    "    df = pd.read_csv(dataset_raw.path)\n",
    "    \n",
    "    #Null value handling\n",
    "    df = df.fillna(df.mean())\n",
    "    \n",
    "    #Normalization\n",
    "    X = df.drop('target' , axis =1)\n",
    "    y = df['target']\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    minMaxScaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(minMaxScaler.fit_transform(X), columns = X.columns)\n",
    "    \n",
    "    X_test = X\n",
    "    y_test = y\n",
    "    \n",
    "    import joblib\n",
    "    skmodel = joblib.load(model.path  + \".joblib\")\n",
    "\n",
    "    y_pred = skmodel.predict(X_test)\n",
    "    \n",
    "    # Place the DataFrames side by side\n",
    "    dataframe = pd.concat([X_test, pd.DataFrame(y_pred,columns=['target'])], axis=1)\n",
    "    \n",
    "    #Query data warehouse and return dataframe\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "\n",
    "    bqclient = bigquery.Client()\n",
    "    table = bigquery.TableReference.from_string(\"microninterview.microndataset.inferenceresults\")\n",
    "    rows = bqclient.list_rows(table)\n",
    "\n",
    "    # Since string columns use the \"object\" dtype, pass in a (partial) schema\n",
    "    # to ensure the correct BigQuery data type.\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    \n",
    "    table_id = \"microninterview.microndataset.inferenceresults\"\n",
    "    #job = bqclient.load_table_from_dataframe(dataframe, table_id, job_config=job_config)\n",
    "    \n",
    "    #job.result()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5491375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\", \"joblib\", \"sklearn\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"deploy_model.yaml\",\n",
    ")\n",
    "def deploy_model(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=project, location=region)\n",
    "\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"model-pipeline\",\n",
    "        artifact_uri = model.uri[:-5],\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "\n",
    "    # Save data to the output params\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef6204a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline.\n",
    "    name=\"mlmd-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    bq_table: str = \"microninterview.microndataset.micronmodeldata\",\n",
    "    output_data_path: str = \"data.csv\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    data_ingestion_task = data_ingestion(bq_table)\n",
    "    \n",
    "    data_preprocessing_task = data_preprocessing(data_ingestion_task.outputs[\"dataset_raw\"])\n",
    "\n",
    "    model_training_task = model_training(data_preprocessing_task.outputs[\"dataset_train\"])\n",
    "    \n",
    "    #model_inference_task = model_inference (data_ingestion_task.outputs[\"dataset_raw\"], \n",
    "    #                                                model=model_training_task.outputs[\"model\"])\n",
    "\n",
    "    evaluation_model_task = evaluation_model(dataset_test=data_preprocessing_task.outputs[\"dataset_test\"],\n",
    "                                             model = model_training_task.outputs[\"model\"])\n",
    "    \n",
    "    with dsl.Condition(\n",
    "          evaluation_model_task.outputs[\"dep_decision\"] == \"true\",\n",
    "          name=\"deploy_decision\",\n",
    "      ):\n",
    "            deploy_task = deploy_model(model=model_training_task.outputs[\"model\"],project=project,region=region)\n",
    "            model_inference_task = model_inference (data_ingestion_task.outputs[\"dataset_raw\"], \n",
    "                                                    model=model_training_task.outputs[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "82fdf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"mlmd_pipeline.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5fa18fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/asia-southeast1/pipelines/runs/mlmd-pipeline-20210919154133?project=microninterview\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api_client = AIPlatformClient(project_id=PROJECT_ID,region=REGION)\n",
    "response = api_client.create_run_from_job_spec('mlmd_pipeline.json',enable_caching= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660004a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ec5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
